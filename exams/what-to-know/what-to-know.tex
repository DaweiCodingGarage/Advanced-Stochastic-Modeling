\documentclass[12pt]{article} 
\input{../../custom}

\title{What to know for midterm \#2}
\author{}
\date{}


\begin{document}
\maketitle

\section{Asymptotics and connections to non-Bayesian approaches (BDA 4)}

\subsection{Consistency}
\begin{itemize}
\item Know the definition of what it means for an estimator to be consistent.
\item Know the definition of what it means for a posterior distribution to be consistent.
%\item In simple univariate cases with conjugate priors, be able to give a mathematical argument showing that the posterior is consistent when the model is correctly specified. (What I mean here is to show it directly using an explicit formula for the posterior---not using general abstract theorems. Hint: You can do this using the law of large numbers and Chebyshev's inequality.)
\item Understand the concept of frequentist analysis of Bayesian methods, in which we ask what properties a given Bayesian procedure would have if the data were generated from some true distribution $P_0$ (which may or may not be a member of the assumed model class).
\item Know that Doob's theorem provides very general conditions under which posterior consistency holds, if the model is correct specified and identifiable. (You do not need to know the details.)
\item Know that when the model is misspecified, the posterior will typically concentrate at the point $\theta^*$ minimizing the KL divergence. 
\end{itemize}

\subsection{Asymptotic normality}
\begin{itemize}
\item Know what it means that the posterior is asymptotically normal, and be able to write down the formula expressing this. In particular, know the mean and covariance matrix of the normal approximation.
\item Be able to derive the formula for asymptotic normality of the posterior, from the Taylor approximation (without rigorous details).
\item In simple cases with univariate $\theta$, be able to analytically compute the mean and variance of the asymptotic normal approximation, for a given likelihood.
\item (Exercise 4 from homework 1) Understand why the posterior on $\phi$ is (typically) asymptotically normal when $\phi = f(\theta)$, and know how the mean and variance of the asymptotic normal distribution change under this transformation.
\item Be able to give an argument for why asymptotic normality of the posterior, plus consistency of the MLE, typically will imply posterior consistency.
\item Understand some of the ways in which posterior consistency and asymptotic normality can fail, and be able to give examples.
\end{itemize}

\subsection{Frequentist coverage}
\begin{itemize}
\item Know the definition of the coverage probability of a confidence region, and have a good intuitive understanding of what it means.
\item Understand why having good frequentist coverage is a desirable property.
\item In simple cases, be able to analytically compute coverage probability.
\item Understand the definition of a posterior credible region (e.g., a  90\% or 95\% credible region).
\item Know the definition of an equal-tailed posterior credible interval.
\item In simple cases, be able to analytically compute an equal-tailed posterior credible interval.
\item Know that posterior credible regions often (but not always) have good frequentist coverage properties.
\item Understand why, if the prior and likelihood are exactly correct, posterior credible regions have frequentist coverage equal to their posterior probability (exercise 15a from homework 1).
\end{itemize}


\section{Model checking and cross-validation (BDA 6 \& 7)}

\subsection{Posterior predictive checking}
\begin{itemize}
\item Understand the idea behind posterior predictive checks.
\item Know how to perform a posterior predictive check and compute a posterior predictive p-value.
\item In simple cases, be able to analytically compute a posterior predictive p-value.
\item Know the definition of the posterior predictive distribution for replicate data sets, and know how to sample from it based on posterior samples.
\item Know how to interpret the results of a posterior predictive check. 
\item Understand that, ideally, p-values are uniformly distributed, so sometimes we will see p-values close to zero or one simply by chance. If we were to compute a large number of p-values, know how many we would expect to see outside a given range.
\item Know that (unfortunately) posterior predictive p-values are not ``true'' p-values in the sense that they are not uniformly distributed, even if the model is correct.
\item Understand why some test statistics/quantities will always be well captured by a given model (and thus are not very informative about model fit), especially in the case of exponential families.
\item Realize that one needs to be careful when modifying the model based on the results of posterior predictive checks, since this can lead to overfitting.
\item Realize that posterior predictive checks represent a sort of internal consistency check, but that they are not an ideal way of evaluating model fit, because they are ``using the data twice''.
\end{itemize}

\subsection{Cross-validation}
\begin{itemize}
\item Understand the idea behind cross-validation---why does it make sense?
\item Know the definition of leave-one-out cross-validation.
\item Know the definition of $k$-fold cross-validation.
\item Know these common choices of loss function for cross-validation: log posterior predictive, 0-1 loss, square loss.
\item Be able to derive the expected loss for a given loss function (taking care to compute it with respect to the true distribution!)
\item Know how to compute a cross-validation estimate of generalization performance.
\item Understand why cross-validation will typically provide a better assessment of performance compared to posterior predictive checks, since CV is not evaluating the model on the same data that was used to fit the model.
\item Understand that if cross-validation is used to choose among multiple models, then in order to assess the performance of the chosen model, it needs to be evaluated on a further held-out set (disjoint from the set of data used for cross-validation).
\end{itemize}


\section{Modeling accounting for data collection (BDA 8)}

\begin{itemize}
\item Be able to recognize situations in which the data collection process is biased in a way that will affect your inferences.
\item Be able to give specific examples of situations in which it is important to model the data collection process.
\item Know the definition of ignorability, as well as the intuitive interpretation of it.
\item Be able to explain the interpretation of the ``potential outcomes'' $y$ and the observation indicators $I$.
\item Know the definition of the ``complete-data likelihood'' in the general setup we considered.
\item Know what distribution to use for posterior inferences about $\theta$ when ignorability does not hold.
\item Be able to derive a formula for this posterior in simple cases.
\item Given a verbal description of a distribution on potential outcomes and a data collection process, be able to write down a reasonably appropriate probabilistic model for it.
\item Know the definitions of the following conditions: missing at random (MAR), missing completely at random (MCAR), strong ignorability, and distinct parameters.
\item Be able to give examples in which these conditions hold or do not hold.
\item Know what implications hold between these different conditions.
\item Be able to prove that strong ignorability implies ignorability.
\item Be able to prove that MAR + distinct parameters implies ignorability.
\end{itemize}



\section{Graphical models (PRML 8)}

\subsection{Directed graphical models (DGMs)}
\begin{itemize}
\item Know what the following terms mean: directed graph, directed acyclic graph (DAG), parents of a vertex.
\item Understand what it means for a probability distribution to respect a given DAG.
\item Be able to write down the factorization implied by a given DAG.
\item Be able to draw the DAG corresponding to a given factorization of a distribution.
\item In simple cases, be able to determine whether a given distribution respects a given DAG.
\item Understand why, for any given probability distribution on $n\geq 2$ variables, there is always more than one DAG respected by the distribution.
\item Understand why, for any given DAG, there is more than one probability distribution that respects it.
\item Be able to give an example of a DAG that is respected by any distribution on $n$ variables.
\item Be able to give an example of a distribution that respects any DAG on $n$ variables.
\item Understand that the directionality of the edges in a directed graphical model does not necessarily reflect causality or temporal order!!!
\end{itemize}

\subsection{Undirected graphical models (UGMs)}
\begin{itemize}
\item Know what the following terms mean: undirected graph, clique, maximal clique.
\item Know what it means for a probability distribution to respect a given undirected graph.
\item Understand why this is equivalent to saying that the distribution is proportional to a product over maximal cliques.
\item Understand why this is equivalent to saying that the distribution is equal to a product over all cliques.
\item In simple cases, be able to determine whether a given distribution respects a given undirected graph.
\item In simple cases, given a distribution, be able to draw an undirected graph that is respected by the distribution.
\end{itemize}

\subsection{DGMs vs UGMs}
\begin{itemize}
\item Understand why using a DGM is sometimes preferable to using a UGM, and be able to give an example.
\item Understand why using a UGM is sometimes preferable to using a DGM, and be able to give an example.
\item Understand that there are some distributions whose conditional independence properties {\bf are not} fully captured by any member of either class of graphical models (directed or undirected).
\item Understand that there are some distributions whose conditional independence properties {\bf are} fully captured by a member of each class of graphical models. Be able to give an example and justify it.
\item Given a drawing of a DAG $G$ and an undirected graph $G'$, and given the knowledge that $p$ respects $G$, be able to determine whether this implies that $p$ respects $G'$.
\item Given a drawing of a DAG $G$ and an undirected graph $G'$, and given the knowledge that $p$ respects $G'$, be able to determine whether this implies that $p$ respects $G$.
\end{itemize}

\subsection{Conditional independence criteria}
\begin{itemize}
\item Understand that a graphical model only implies independence properties---it does not necessarily imply any dependence properties.
\item Understand the separation criterion for undirected graphical models.
\item Given a UGM and disjoint subsets of vertices $A,B,C$, be able to determine whether the UGM implies that $X_A \perp X_B \mid X_C$.
\item Understand that if the separation criterion does not apply, then we cannot determine (from the graph alone) whether $X_A \perp X_B \mid X_C$. In particular, this does not imply that the variables are necessarily dependent!
\item Know the definition of the moralization (or moral graph) of a DAG.
\item Given a DAG, be able to draw the corresponding moral graph.
\item Know the meaning of the following terms: set of ancestors, subgraph of ancestors.
\item Understand the moral ancestral separation criterion for directed graphical models.
\item Given a DGM and disjoint subsets of vertices $A,B,C$, be able to determine whether the DGM implies that $X_A \perp X_B \mid X_C$.
\item Understand that if the moral ancestral separation criterion does not apply, then we cannot determine (from the graph alone) whether $X_A \perp X_B \mid X_C$. In particular, this does not imply that the variables are necessarily dependent!
\item Understand the proof of the separation criterion for UGMs (from your homework).
\item Understand the proof of the moral ancestral separation criterion for DGMs (from your homework).
\end{itemize}


\section{Hidden Markov Models (PRML 13)}

\subsection{Setup}
\begin{itemize}
\item Know the definition of a Markov chain.
\item Know the DGM and UGM corresponding to the definition of a Markov chain. Be able to show that the definition of a Markov chain is equivalent to respecting this DGM, and is also equivalent to respecting this UGM.
\item Know the definition of a hidden Markov model (HMM) in terms of the factorization of the distribution.
\item Know the DGM and UGM corresponding to the factorization definition of a HMM. Be able to show that the factorization definition of a HMM is equivalent to respecting this DGM, and is also equivalent to respecting this UGM.
\item Understand the kinds of applications in which HMMs are useful.
\item Know the meaning of following terms: hidden state, initial distribution, transition matrix, emission distributions.
\item Be able to give examples of HMMs and be able to identify when a given model is an HMM.
\end{itemize}

\subsection{Viterbi algorithm}
\begin{itemize}
\item Understand the goal of the Viterbi algorithm.
\item Be able to give examples of applications in which the Viterbi algorithm would be useful.
\item Know the computational complexity of the Viterbi algorithm, and understand why it is advantageous over the naive approach of maximizing over all sequences.
\item Understand how to derive the Viterbi algorithm, and be able to derive it  from the general principle of writing down the formula for maximizing the probability and looking for recursions. (NOTE: Just memorizing the derivation is not sufficient---you must understand how to derive it so that you can apply the same principles to new situations.)
\item Be able to derive both the part for computing the max as well as for computing an argmax.
\item Understand why the algorithm is guaranteed to find an argmax (a maximizing sequence).
\item Once you have identified the recursions, be able to write down the algorithm in pseudocode.
\item Be able to derive the computational complexity of the algorithm, based on the description of the algorithm. (Again, it is insufficient to memorize it, you need to understand how it is derived.)
\item Understand the issue of arithmetic underflow/overflow.
\item Understand how to fix the issue of arithmetic underflow/overflow using logs.
\item Be able to derive the modified algorithm using logs.
\end{itemize}

\subsection{Forward-backward algorithm}
\begin{itemize}
\item Understand the goal of the forward-backward algorithm (i.e., the forward and backward algorithms, together).
\item Understand how the results of the forward and backward algorithms enable you to compute many quantities of interest regarding the conditional distribution on the hidden variables given the observed data.
\item Understand how to sample from the conditional distribution on the hidden variables given the observed data, using the results of the forward and backward algorithms.
\item Understand how the forward algorithm enables you to predict future data, and be able to write down the posterior predictive distribution in terms of the results from the forward algorithm.
\item Understand how to derive both the forward algorithm and the backward algorithm, and be able to derive them from the general principle of writing down the formula for computing the normalization constant and looking for recursions. (NOTE: Again, just memorizing the derivation is not sufficient---you need to understand how to derive it.)
\item Once you have identified the recursions, be able to write down the algorithm in pseudocode.
\item Be able to derive the computational complexity of the algorithm, based on the description of the algorithm.
\item Understand the issue of arithmetic underflow/overflow in the forward and backward algorithms.
\item Understand how to derive the log-sum-exp trick.
\item Understand why the log-sum-exp trick solves the issue of arithmetic underflow/overflow.
\end{itemize}

  


\end{document}






